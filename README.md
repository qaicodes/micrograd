# Micrograd

Micrograd is a minimalistic implementation of a neural network library inspired by Andrej Karpathy's tutorials on YouTube. This project aims to provide a clear and concise understanding of the fundamental concepts behind backpropagation and neural networks.

## Features

- **Simple and Lightweight**: The codebase is designed to be as simple as possible, making it easy to understand and extend.
- **Educational**: Ideal for learning and experimenting with the core principles of neural networks and backpropagation.
- **Fully Connected Layers**: Supports basic fully connected neural network layers.

## Getting Started

### Prerequisites

- Python 3.x

### Installation

Clone the repository:

```bash
git clone https://github.com/yourusername/micrograd.git
cd micrograd
```

### Usage

You can start by running the example script to see a simple neural network in action:

```bash
python example.py
```

### Tutorials

For a detailed walkthrough, refer to Andrej Karpathy's tutorials on YouTube, which explain the concepts and code step-by-step.

## Contributing

Contributions are welcome! Please feel free to submit a pull request or open an issue.

## License

This project is licensed under the MIT License.

## Acknowledgements

- Andrej Karpathy for his insightful tutorials and inspiration.
